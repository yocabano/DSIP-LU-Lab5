# DSIP FieldLab5 - SafeVoice
Data Science In Practice Course FieldLab 5 

## Description
**SafeVoice** is a data pipeline application designed to transform raw human trafficking incident reports into semantic RDF triples. Built as part of the 2025 Data Science in Practice (DSIP) course, this application manages the below data lifecycle:

* **Data Entry UI**: A user interface for submitting reports.

* **Data Cleaning**: Automated data cleaning and anonymization of raw inputs.

* **RDF Mapping**: Transformation of data into RDF N-Triples.

* **Ingestion**: Direct upload of RDF N-Triples to an AllegroGraph server.

## Project Structure

This project follows a modular architecture to separate the user interface, data processing, and storage logic.

```
SAFEVOICE project/
├── app.py                      # Main application entry point (Streamlit UI)
├── requirements.txt            # Python dependencies
├── config/
│   ├── yml_mapping.yml         # YARRRML configuration mapping flat data to RDF
│   └── CDM schemas...csv       # Common Data Model schema for UI and data type conversion
├── data/
│   ├── raw/                    # Stores raw JSON reports generated by the UI
│   ├── intermediate/           # Staging area for generated .nt RDF files
│   └── processed/              # Archive for successfully ingested files; acts as the data source for the JSON report overview in the UI
└── src/
    ├── orchestrator/
    │   └── pipeline.py         # The central controller script that manages the flow of data from cleaning to mapping to ingestion
    ├── cleaning/
    │   └── cleaner.py          # Handles data cleaning, type casting, and location anonymization
    ├── transform/
    │   └── mapper.py           # Converts clean DataFrames into RDF triples using the YAML config
    └── storage/
        └── ingest.py           # Handles connection and upload RDF triples to the AllegroGraph server
```

* **`app.py`**: The main entry point. Runs the Streamlit UI, collects user reports, and triggers the pipeline.
* **`src/orchestrator/pipeline.py`**: The central controller that manages the flow of data from cleaning to transformation to ingestion.
* **`src/cleaning/cleaner.py`**: Validates raw input against the CDM schema and handles missing values or type conversions.
* **`src/transform/mapper.py`**: Converts the cleaned flat data into RDF N-Triples using the YARRRML mapping configuration.
* **`src/storage/ingest.py`**: Handles the connection to the AllegroGraph server and uploads the generated RDF files.
* **`config/`**: Contains the CDM schema CSV and the YARRRML mapping file.
* 
## Getting Started

### Prerequisites

* **Python 3.13**
* **AllegroGraph Server** (Cloud or Local)
* Required Python packages (listed in `requirements.txt`):
    * streamlit
    * numpy
    * pandas
    * PyYAML
    * agraph-python


### Installing

1. Create your AllegroGraph server
2. Clone the repo
   ```sh
   git clone https://github.com/github_username/repo_name.git
   ```
3.  **Install dependencies:**
    ```sh
    pip install -r requirements.txt
    ```
    *Alternatively, install manually:*
    ```sh
    pip install pandas numpy streamlit PyYAML agraph-python
    ```
4. Enter your AllegroGraph server credentails in `ingest.py`
   ```
   # --- Server Configuration Constants ---
    # NOTE : Please replace your server credentials here
    AG_HOST = "<YOUR HOST>"
    AG_PORT = "443"
    AG_USER = "<YOUR USER>"
    AG_PASSWORD = "<YOUR PASSWORD>"
    AG_CATALOG = "<YOUR CATALOG>"
   ```
   
### Executing program

## Authors
Contributors names and contact info

ex. Dominique Pizzie
ex. @DomPizzie

## License



