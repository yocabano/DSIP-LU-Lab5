# DSIP FieldLab5 - SafeVoice
Data Science In Practice Course FieldLab 5 

## Description
**SafeVoice** is a data pipeline application designed to transform raw human trafficking incident reports into semantic RDF triples. Built as part of the 2025 Data Science in Practice (DSIP) course, this application manages the below data lifecycle:

* **Data Entry UI**: A user interface for submitting reports.

* **Data Cleaning**: Automated data cleaning and anonymization of raw inputs.

* **RDF Mapping**: Transformation of data into RDF N-Triples.

* **Ingestion**: Direct upload of RDF N-Triples to an AllegroGraph server.

## Project Structure

This project follows a modular architecture to separate the user interface, data processing, and storage logic.

```
SAFEVOICE project/
├── app.py                      # Main application entry point (Streamlit UI)
├── requirements.txt            # Python dependencies
├── config/
│   ├── UI_drop_downs.csv       # Defines UI dropdown options
│   ├── yml_mapping.yml         # YARRRML configuration mapping dataframe to RDF
│   └── Data schemas CDM...csv  # Common Data Model schema
├── data/
│   ├── raw/                    # Stores raw JSON reports generated by the UI
│   ├── intermediate/           # Staging area for generated .nt RDF files
│   └── processed/              # Archive for successfully ingested files; acts as the data source for the JSON report overview in the UI
└── src/
    ├── orchestrator/
    │   └── pipeline.py         # The central controller script that manages the flow of data from cleaning to mapping to ingestion
    ├── cleaning/
    │   └── cleaner.py          # Handles data cleaning, type casting, and location anonymization
    ├── transform/
    │   └── mapper.py           # Converts clean DataFrames into RDF triples using the YAML config
    └── storage/
        └── ingest.py           # Handles connection and upload RDF triples to the AllegroGraph server
```

- **`app.py`**: Serves as the user interface and entry point for the SafeVoice application. It allows sources to submit reports, view their submitted reports, and triggers the data processing pipeline.
- **`src/orchestrator/pipeline.py`**: Acts as the central orchestrator, managing the full data flow from cleaning and transformation to ingestion.
- **`src/cleaning/cleaner.py`**: Converts raw input data into the correct data types based on the CDM schema (located under `/config` and configurable), and performs preprocessing steps such as geodata anonymization.
- **`src/transform/mapper.py`**: Converts the cleaned data into RDF N-Triples using the provided YARRRML mapping configuration (located under `/config` and configurable).
- **`src/storage/ingest.py`**: Manages the connection to the AllegroGraph server and uploads the generated RDF files to the source-specific repository (e.g., `001_repo`).
- **`config/`**: Contains the UI dropdown CSV file, the CDM schema CSV file, and the YARRRML mapping configuration file.

## Getting Started

### Prerequisites

* **Python 3.13**
* **AllegroGraph Server** (Cloud or Local)
* Required Python packages (listed in `requirements.txt`):
    * streamlit
    * numpy
    * pandas
    * PyYAML
    * agraph-python


### Installing

1. Clone the repo
   ```sh
   git clone https://github.com/yocabano/DSIP-LU-Lab5.git
   ```
2.  **Install dependencies:**
    ```sh
    pip install -r requirements.txt
    ```
    *Alternatively, install manually:*
    ```sh
    pip install pandas numpy streamlit PyYAML agraph-python
    ```
3. Create your AllegroGraph server to store the triples
4. Replace your AllegroGraph server credentails in `ingest.py`
   ```
   # --- Server Configuration Constants ---
    # NOTE : Please replace your server credentials here
    AG_HOST = "<YOUR HOST>"
    AG_PORT = "443"
    AG_USER = "<YOUR USER>"
    AG_PASSWORD = "<YOUR PASSWORD>"
    AG_CATALOG = "<YOUR CATALOG>"
   ```
5. Replace your UI dropdown file name and path in `app.py`
   ```
   # --- CONFIGURATION ---
    DROP_DOWN_FILE_PATH = "config/UI_drop_downs.csv" # csv file to define the drop-downs in the UI
    BASE_JSON_FOLDER_RAW = "data/raw/raw_json_record" # directory to store the raw json files generated by the UI
    BASE_JSON_FOLDER_PROCESSED = "data/processed/processed_json_record" # directory to store the successfully ingested json files
   ```
   
6. Replace your CDM file name and path in `cleaner.py`
   ```
   # --- CONFIGURATION ---
   # CDM file path
   CDM_FILE_PATH = 'config/Data schemas_CDM - Fieldlab 5 - Human trafficking sources EEPA.csv'
   ```

7. Replace your YARRRML mapping file name and path in `mapper.py`
   ```
   # --- Configuration ---
   # Define the expected location of the YML mapping file
   YML_MAPPING_PATH = os.path.join("config", "yml_mapping.yml")
    
   # Define the intermediate data path for .nt files
   # This is where the RDF files will be stored before ingestion
   INTERMEDIATE_DIR = os.path.join("data", "intermediate")
   ```
   
### Executing program
```sh
streamlit run app.py
```
## Application Usage Guide (for sources)

This guide provides instructions for end-users (sources) on how to submit a new report and view the successfully submitted reports.

### A. Submitting a New Report

1. **Navigate:** Select **“Submit Report”** from the sidebar.
2. **Enter Source ID:** In the sidebar, enter your unique **Source ID** (e.g., `#001`). This field is required to submit reports and ensures that you can only view your own submissions.
3. **Complete the Form:** The form is divided into five logical sections:
   - **Record Details:** Auto-generated Record ID (editable) and relevant dates.  
      > **:exclamation:Tip:** The Record ID is required to submit the report.
   - **Victim Demographics:** Enter details such as ID, age, gender, and nationality.  
      > **:exclamation:Tip:** The Victim ID is required to submit the report.
   - **Movement & Incident:** Describe the **departure** and **destination** locations.
   - **Trafficker Information:** Enter available information about the trafficker.  
      > **:exclamation:Tip:** The Trafficker ID is required to submit the report.
   - **Publication:** Provide information related to the publication.
4. **Submit the Report:**
   - Click the **“Submit Report”** button at the bottom of the page.
     > **:exclamation:Tip:** Submitted records are **immutable** and cannot be edited. To correct an error, please submit a new report with the correct information.
   - A message box will appear indicating that the report has been submitted. If the data is successfully processed and saved, a **“Success”** message will be displayed. If an error occurs, please contact support and include the error message.

---

### B. Managing & Viewing Reports

1. **Navigate:** Select **“Manage Reports”** from the sidebar.
2. **View Submission History:** A table will display all reports previously submitted under your **Source ID**.
3. **Filter Reports:**
   - Expand the **“Filter Records”** section.
   - Select a column (e.g., `victim_nationality`) and choose one or more values (e.g., `Eritrea`) to refine the results.

## Authors
| Name | Github Username | 
| :---- | :------------------- |
|DA    |duyanhtrinh| 
|Mihir |mihirramani|
|Nurifeiya |nurifeiya|
|Stephanie |yocabano|
|Xiong |arashikuma|

## License
[MIT License](https://gh.io/mit)


